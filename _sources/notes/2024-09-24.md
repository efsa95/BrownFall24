---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.4
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Cleaning Data - Structure


## Intro

This week, we'll be cleaning data.

Cleaning data is **labor intensive** and requires making *subjective* choices.  
We'll focus on, and assess you on, manipulating data correctly, making reasonable
choices, and documenting the choices you make carefully.

We'll focus on the programming tools that get used in cleaning data in class
this week:
- reshaping data
- handling missing or incorrect values
- renaming columns


```{code-cell} ipython3
import pandas as pd
import seaborn as sns

# make plots look nicer and increase font size
sns.set_theme(font_scale=2, palette='colorblind')
```

Note here we set the `theme` and pass the palette and font size as paramters.
To learn more about this and the various options, see the [seaborn aesthetics tutorial](https://seaborn.pydata.org/tutorial/aesthetics.html)

## What is Tidy Data?

Read in the three csv files described below and store them in a dictionary


```{code-cell} ipython3
url_base = 'https://raw.githubusercontent.com/rhodyprog4ds/rhodyds/main/data/'

data_filename_list = ['study_a.csv','study_b.csv','study_c.csv']
```

Here we can use a dictionary comprehension

```{code-cell} ipython3
example_data = {datafile.split('.')[0]:pd.read_csv(url_base+datafile) for datafile in data_filename_list}
```

- this is a *dictionary comprehension* which is like a list comprehension, but builds a
dictionary instead. 
- `split` is a string method that splits the string at the given character and returns a list
- `[0]` then takes the first item out
- `:` makes the part to the left a key and rigt the value
- we can add strings to combine them

### Breakign down that comprehension

```{tip}
This section also illustrates a way you can work to understand **any** piece of code:
*take small sections and run them one at a time*
```

We can do smaller examples of each step. 

First a tiny dictionary comprehension
```{code-cell} ipython3
{char:ord(char) for char in 'abcdef'}
```
this gives us the ascii number for each character in that string with the `char` as key and `ord(char)`'s *output* as the value. Note that it *runs* the code assigned in the value because of the `()` doing the function call.

Next the split method, we will use this sentence. 

```{code-cell} ipython3
sentence = 'Next the split method, we will use this sentence.'
type(sentence), len(sentence)
```

this is type `str` so we can use the [string class methods](https://docs.python.org/3/library/stdtypes.html#string-methods) in Python, such as [`split`](https://docs.python.org/3/library/stdtypes.html#str.split). 
As a `str` the `len` function tells us how many *characters* because a string is iterable over characters. 
We used this fact in the tiny dictionary above. 

By default it splits at spaces
```{code-cell} ipython3
sentence.split()
```
we can instead tell it on what string to split
```{code-cell} ipython3
clauses = sentence.split(',')
type(clauses)
```

`split` always returns a list, so we can pick the first item with `[0]`
```{code-cell} ipython3
clauses[0]
```

We can concatenate `str` objects with `+`
```{code-cell} ipython3
title = 'Dr.'
last = 'Brown'
title + last
```

### the same data 3 ways

We can pick a single on out this way
```{code-cell} ipython3
example_data['study_a']
```

or with an additional import, 

````{margin}
```{note}
[Ipython](https://ipython.org/)
is the python *interpreter* that we are using, provides the fancy formatting that the `print` function does 
not do with its [`display`](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.display)
```
````

```{code-cell} ipython3
from IPython.display import display
```
THen we can iterate over the values in the dictionary ( the three dataframes) and see them all: 
```{code-cell} ipython3
[display(df) for df in example_data.values()];
```



These three all show the same data, but let's say we have two goals:
- find the average  effect per person across treatments
- find the average effect per treatment across people

This works differently for these three versions.

For `study_a` we can easilty get the average per treatment, but to get the 
average per person, we have to go across rows, which we can do here, but doesn't work as well with plotting

we can work across rows with the `axis` parameter if needed

For B,  we get the average per person, but what about per treatment? again we have to go across rows instead.

For the third one, however, we can use groupby, because this one is tidy. 

## Encoding Missing values

We can see the impact of a bad choice to represent a missing value with `-`
```{code-cell} ipython3
example_data['study_c'].dtypes
```
one non numerical value changed the whole column!

```{code-cell} ipython3
example_data['study_c'].describe()
```
so `describe` treats it all like categorical data

We can use the `na_values` parameter to fix this. Pandas recognizes a lot of different
values to mean missing and store as `NaN` but his is not one. Find the full list 
in the [`pd.read_csv` documentation of the `na_values` parameter](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#:~:text=of%20large%20files.-,na_values,-Hashable%2C%20Iterable%20of)

```{code-cell} ipython3
example_data = {datafile.split('.')[0]:pd.read_csv(url_base+datafile,na_values='-') 
                for datafile in data_filename_list}
```
now we can checka gain
```{code-cell} ipython3
example_data['study_c'].dtypes
```
and we see that it is `float` this is because `NaN` is a float. 

```{code-cell} ipython3
example_data['study_c']
```
Now it shows as Nan here

## Computing on Tidy Data
So we can see how to compute on this data to compute both ways. 

```{code-cell} ipython3
example_data['study_c'].groupby('person')['result'].mean()
```

```{code-cell} ipython3
example_data['study_c'].groupby('treatment')['result'].mean()
```
The original [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) paper is worth reading to build a deeper understanding of these ideas.  


## Tidying Data


Let's reshape the first one to match the tidy one. First, we
will save it to a DataFrame, this makes things easier to read
and enables us to use the built in help in jupyter, because it can't check types too many levels into a data structure.

Before
```{code-cell} ipython3
example_data['study_a']
```

After
```{code-cell} ipython3
df_a = example_data['study_a']
```

When we melt a dataset:
- the `id_vars` stay as columns
- the data from the `value_vars` columns become the values in the `value` column
- the column names from the `value_vars` become the values in the `variable` column
- we can rename the value and the variable columns.

```{code-cell} ipython3
tall_a = df_a.melt(id_vars='name',var_name='treatment',value_name='result')
tall_a
```

[see visualized on pandas tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20'''%0Aname,treatmenta,treatmentb%0AJohn%20Smith,,2%0AJane%20Doe,16,11%0AMary%20Johnson,3,1%0A'''%0A%0Astudy_a%20%3D%20pd.read_csv%28io.StringIO%28csv%29%29%0A%0Astudy_a.melt%28id_vars%3D'name',var_name%3D'treatment',value_name%3D'result'%29&d=2024-09-25&lang=py&v=v1)

# Transforming the Coffee data

First we see another way to filter data. We can use statistics of the data to filter and remove some. . 

For exmaple, lets only keep the data from the top 10 countries in terms of number of bags. 

```{code-cell} ipython3
arabica_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/arabica_data_cleaned.csv'
# load the data
coffee_df = pd.read_csv(arabica_data_url)
coffee_df.head()
```

We have separate countries for the country and number of bags

So we  make a table the totals how many bags per country
```{code-cell} ipython3
bags_per_country = coffee_df.groupby('Country.of.Origin')['Number.of.Bags'].sum()
bags_per_country.head(15) 
```

Then we can take only the highest 10, and keep only the index
```{code-cell} ipython3
# sort descending, keep only the top 10 and pick out only the country names
top_bags_country_list = bags_per_country.sort_values(ascending=False)[:10].index

# filter the original data for only the countries in the top list
top_coffee_df = coffee_df[coffee_df['Country.of.Origin'].isin(top_bags_country_list)]
```

we can see which countries are in the list
```{code-cell} ipython3
top_bags_country_list
```

and confirm that is all that is in our new dataframe
```{code-cell} ipython3
top_coffee_df['Country.of.Origin'].value_counts()
```

compared to the original, it is far fewer
```{code-cell} ipython3
:tags: ["scroll-output"]
coffee_df['Country.of.Origin'].value_counts()
```


```{warning}
This section is changed slightly from in class to be easier to read. 
```

This limits the rows, but keeps all of the columns
```{code-cell} ipython3
top_coffee_df.columns
```

Since this has a lot of variables, we will make lists of how we want to use different columns
in variables before using. 
```{code-cell} ipython3
value_vars = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',
       'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', ]
id_vars = ['Species', 'Owner', 'Country.of.Origin']
coffee_tall = top_coffee_df.melt(id_vars=id_vars, value_vars=value_vars,
              var_name='rating')
coffee_tall.head(1)
```

This data is "tidy" all of the different measurements (ratings) are different rows and we have a few 
columsn that identify each sample 

This version plays much better with plots where we want to compare the ratings. 
````{margin}

```{tip}
Copy this cell and run it, then cut out one parameter at a time to get before/after to see more visually what each one does
```
````
```{code-cell} ipython3
sns.catplot(data = coffee_tall, col='rating', y='value',x='Country.of.Origin',
            hue='Country.of.Origin',aspect=3, col_wrap =3, kind='violin') 
```

This now we can use the `rating` as a variable to break the data by in our subplots. 
I did a few new things in this: 
- a [violin plot](https://seaborn.pydata.org/tutorial/categorical.html#violinplots) allows us to compare how different data is distributed. 
- I used both `col` and `col_wrap`, `col` alone would have made nine columns, and without `row` all in one row. `col_wrap` says to line wrap after a certain number of columns (here 3)
- `aspect` is an attribute of the [figure level plots](https://seaborn.pydata.org/tutorial/function_overview.html#figure-level-vs-axes-level-functions) that controls the ratio of width to height (the aspect ratio). so `aspect=3` makes it 3 times as wide as tall in each subplot, this spreads out the x tick labels so can read them 


## Questions After Class 


Most  of the questions today were about assignment 3 or asking to explain specific things 
that are above. Feel free to post an issue if a question comes up later. 

### Can you change the locations of the names next to a plot? 

First, see the annotated graph and learn the technical name of the element you want to move. 


![annotated graph](https://matplotlib.org/stable/_images/sphx_glr_anatomy_001.png)

the above figure come from [matplotlib's Anatomy of a Figure](https://matplotlib.org/stable/gallery/showcase/anatomy.html) page which includes the *code* to generate that figure

You can control each of these but you may need to use `matplotlib`. 

If this means the legend, seaborn can control that location. If it refers to fixing overlappign tick labels, I demonstrated that above, with `aspect`. 