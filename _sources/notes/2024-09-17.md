---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Exploratory Data Analysis

Now we get to start actual data science!


## This week: Exploratory Data Analysis


- How to summarize data
- Interpretting summaries
- Visualizing data
- interpretting summaries


### Summarizing and Visualizing Data are **very** important

- People cannot interpret high dimensional or large samples quickly
- Important in EDA to help you make decisions about the rest of your analysis
- Important in how you report your results
- Summaries are similar calculations to performance metrics we will see later
- visualizations are often essential in debugging models


**THEREFORE**
- You have  [a lot of chances](https://rhodyprog4ds.github.io/BrownFall22/syllabus/achievements.html#assignments-and-skills) to earn summarize and visualize
- we will be picky when we assess if you earned them or not


```{code-cell} ipython3
import pandas as pd
```

Today we will work with a new dataset about Carbon emissions

```{code-cell} ipython3
carbon_data_url = 'https://github.com/rfordatascience/tidytuesday/raw/master/data/2024/2024-05-21/emissions.csv'
```

```{code-cell} ipython3
carbon_df = pd.read_csv(carbon_data_url)
```

[data readme](https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-05-21/readme.md)

```{code-cell} ipython3
carbon_df.head()
```

In this case, `head`  shows that these rows are very similar because it is sorted.  Tail would probably be similar, so we will try `sample` to get a random subset. 

```{code-cell} ipython3
carbon_df.sample(5)
```

## Describing a Dataset

So far, we've loaded data in a few different ways and then we've examined
DataFrames as a data structure, looking at what different attributes they have
and what some of the methods are, and how to get data into them.


The [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) method provides us with a set of summary statistics that broadly


````{margin}
```{admonition} further reading
On the [documentation page for describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) the "<i class="fas fa-info-circle"></i>
 See Also" shows the links to the documentation of most of the individual functions.  This is a good way to learn about other things, or find something when you are not quite sure what it would be named.  Go to a function thats similar to what you want and then look at the related functions.
```
````

```{code-cell} ipython3
carbon_df.describe()
```

<!-- From this, we can draw several conclusions. For example:
-   -->

And these all give us a sense of the values and the distribution or spread fo the data in each column.

### Individual statistics
We can also extract each of the statistics that the `describe` method calculates individually, by name.  


```{code-cell} ipython3
carbon_df.max()
```


### Understanding Quantiles

The 50% has another more common name: the median.  It means 50% of the data are lower (and higher) than this value.  


The quantiles
are tricky, we cannot just `.25%()` to get the 25% percentile, we have to use the
`quantile` method and pass it a value between 0 and 1.

```{code-cell} ipython3
carbon_df['production_value'].quantile(.25)
```

```{code-cell} ipython3
carbon_df['production_value'].quantile(.8)
```


## Individual variable

We can use the descriptive statistics on individual columns as well

## What is the average total emissions in this dataset?

```{code-cell} ipython3
carbon_df['total_emissions_MtCO2e'].mean()
```

## Working with categorical data


There are different columns in the describe than the the whole dataset:
```{code-cell} ipython3
carbon_df.columns
```

So far, the stats above are only for numerical features. 


We can get the prevalence of each one with `value_counts`, this can also allow us to answer certain questions. Let's try a few. 


### What is the most common parent type?

```{code-cell} ipython3
carbon_df['parent_type'].value_counts()
```

````{margin}
```{hint}
This file works as a notebook, that gets run when the HTML is built for the site. 
Here, I used the [glue feature](https://jupyterbook.org/en/stable/content/executable/output-insert.html#glue-gluing) to use a value from the code cell in the markdown
```
````

```{code-cell} ipython3
:tags: ["hide-input"]
from myst_nb import glue
most_common_ptype = carbon_df['parent_type'].value_counts().idxmax()
glue('max_parent',most_common_ptype)
```

This shows us that the most common one is {glue:}`max_parent`

We also notice that the data is relatively balanced enough that we can make good comparisons from the overall output.

For the specific question, we could instead use the `mode` method (the most frequent value).

```{code-cell} ipython3
carbon_df['parent_type'].mode()
```

### Is it reasonable to compare and use all of the the `commodity` types in the data

To do this, we again look at the value counts:

```{code-cell} ipython3
carbon_df['commodity'].value_counts()
```

Here, we note that the top few are a lot more similar and the smallest one is a lot lower.  Here we might drop only the bottom couple or keep them call becaus for a lot of things 200 measurements is enough. 

Another choice is that we could combine the different types of coals together.  We can do this by adding a column.

```{code-cell} ipython3
carbon_df['commodity_simple'] = carbon_df['commodity'].apply(lambda s: s if not('Coal' in s) else 'Coal')
```

The way this works is:
- `carbon_df['commodity']` picks out the column of interest 
- [the `.apply` method](https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html) applies a function (that we pass to it) to all of the elements of a series (or to the rows or columns of a [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html))
- `lambda s: s if not('Coal' in s) else 'Coal'` is a lambda function that returns the same value if Col is not in it or only `Coal` if it is
- assigns values to a column `'commodity_simple'` `carbon_df['commodity_simple'] =`. It also creates that column since it did not exist


### understanding lambda functions
To better understand the lambda function that we  used above, let's assign it to a variable. 

```{code-cell} ipython3
coal_strip = lambda s: s if not('Coal' in s) else 'Coal'
```

First we will inspect it a little:
```{code-cell} ipython3
type(coal_strip)
```

We can see it is a function here

Now we can make calls to it, like any other functions

```{code-cell} ipython3
coal_strip('Metallurgical Coal')
```

this works and now we test the other case:

```{code-cell} ipython3
coal_strip('naything else')
```

### How a column is added

Now we can see a sample of the DataFrame again to see how the `apply` method works.

```{code-cell} ipython3
carbon_df.sample(5)
```

We can further examine this column:
```{code-cell} ipython3
carbon_df['commodity_simple'].value_counts()
```

Now the numbers are more similar, we might want to drop the cement, we can do that using a mask that we saw last week. 

## Split-Apply-Combine


![split-apply-combine](https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png)

see it in action on [pandas tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20'''%0Abreed,type,longevity,size%0ALabrador,sporting,12.04,medium%0AGerman,herding,9.73,large%0ABeagle,hound,12.3,small%0AGolden,sporting,12.04,medium%0AYorkshire,toy,12.6,small%0ABulldog,non-sporting,6.29,medium%0ABoxer,working,8.81,medium%0APoodle,non-sporting,11.95,medium%0A'''%0A%0Adogs%20%3D%20pd.read_csv%28io.StringIO%28csv%29%29%0Adogs%20%3D%20dogs%5B%5B'breed',%20'size',%20'longevity'%5D%5D.sort_values%28'size'%29%0A%0Adogs.groupby%28'size'%29.mean%28%29&d=2024-09-17&lang=py&v=v1)

### Which commodity type has the highest average emissions?

To do this we group by the categorical value, the new simplified commodity column we created, then we pick out thee emissions column, and take the average. 

```{code-cell} ipython3
carbon_df.groupby('commodity_simple')['total_emissions_MtCO2e'].mean()
```

### How apply works

We can use `apply` with any function, that we write in advance, that comes from a library, or is built in.  Above, we used a lambda we defined on the fly, but here we can make it first.
```{code-cell} ipython3
def first_chars(s):
  return s[:5]

carbon_df['commodity'].apply(first_chars)
```

### Grouping Multiple times

we can pass a list to group by two values
```{code-cell} ipython3
carbon_df.groupby(['commodity_simple','parent_type'])['total_emissions_MtCO2e'].mean()
```

This is one Series, but is has a [multi-index](https://pandas.pydata.org/docs/user_guide/advanced.html). We can check the type
```{code-cell} ipython3
em_by_comm_parent = carbon_df.groupby(['commodity_simple','parent_type'])['total_emissions_MtCO2e'].mean()
type(em_by_comm_parent)
```

and look at the index to confirm
```{code-cell} ipython3
em_by_comm_parent.index
```

We can use `reset_index` to change from the multi-index into a new count from 0 index (and make it a DataFrame in the process)

```{code-cell} ipython3
carbon_df.groupby(['commodity_simple','parent_type'])['total_emissions_MtCO2e'].mean().reset_index()
```

## Prepare for next class

Seaborn is a plotting library that gives us [*opinionated defaults*](https://seaborn.pydata.org/tutorial/introduction.html#opinionated-defaults-and-flexible-customization)

```{important}
Run this line one time before class on Thursday
```

```{code-cell} ipython3
import seaborn as sns
```

If you get `ModuleNotFound` error, open a terminal tab and run `pip install seaborn` . 

seaborn's alias is `sns` as an inside joke among the developers to the character, [Samual Norman Seaborn](https://en.wikipedia.org/wiki/Sam_Seaborn) from West Wing they named the library after [per their FAQ](https://seaborn.pydata.org/faq.html#why-is-seaborn-imported-as-sns)


```{code-cell} ipython3

```

## Questions After Class

```{important}
Questions about the assignment have been addreessed by adding hints and tips to the end of the [instructions](../assignments/02-python-access.md)
```

### when putting the two column names `["commodity_simple", "parent_type"]` in the square brackets, what did that do?

We cann answer a question like this by inspecting the code further

First we can look directly at it:
```{code-cell} ipython3
["commodity_simple", "parent_type"]
```

Next, we can check its type:
```{code-cell} ipython3
type(["commodity_simple", "parent_type"])
```

It makes a `list` which is then compatible with the   `groupby` method. 

We can look a its help to remember what it can be passed:
```{code-cell} ipython3
# the __doc__ attribute is a property of all functions
# it is a string so I used split to break it into lines, 
# looked to see how many i needed then joined them back together
# and printed them (to have the newkines render)
print('\n'.join(carbon_df.groupby.__doc__.split('\n')[:18]))
```



### How does the  apply function work?

I have explained it and linked resources above, plus the `pandas` docs 
have a [section on it in their user guide](https://pandas.pydata.org/docs/user_guide/groupby.html#flexible-apply)

### How should we be practicing this material. Its hard to tell whats the specific take away from this class vs memorizing methods.

Review the notes and see the analysis. 

What we did is ann example data anlysis. We asked and answered several questions.  This serves as example questions and types of questions. How to interpret the statistics. 


### what does the lambda do inside of the function we created to group the coal commodity

`lambda` is the keyword to define a function in line, like `def` is in a full length definition.



### Is there a way to scrape data from a website and make it a csv file if the website does not allow for exporting?

Sometimes, we will learn webscraping in a few weeks. For now, download locally, or try a different dataset.

### Will be working on forms of data visualization?

Yes